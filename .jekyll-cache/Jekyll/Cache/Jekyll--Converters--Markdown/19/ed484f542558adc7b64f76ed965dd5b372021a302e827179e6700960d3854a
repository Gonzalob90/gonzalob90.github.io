I"}<h1 id="h1-heading">H1 heading</h1>

<h3 id="h3-heading">H3 heading</h3>

<p>Basic text</p>

<p>What about a <a href="https://google.com">link</a></p>

<p><img src="http://localhost:4000/images/population.png" alt="population coding" /></p>

<p>The intuition behind this metric is that synergy should be defined as the “whole beyond the 
maximum of its parts”. The whole is described as the mutual information between the joint $\textbf{X}$ 
and the outcome Y; whereas the maximum of all the possible subsets is interpreted as the maximum information 
that any of the sources $\sA_{i}$ provided about each outcome. Formally, this is stated as:</p>

<script type="math/tex; mode=display">\require{physics}</script>

<script type="math/tex; mode=display">S_{max}(\{X_{1},X_{2},...,X_{n}\};Y) = I(X; Y) - \sum_{y \in Y} p(Y=y) \max_{i} KL \big[\ P(A_{i} | y) \Vert P(A_{i}) \big]\</script>

<script type="math/tex; mode=display">I(\mathbb{A}_{i};Y=y) = \sum_{a_{i} \in \mathbb{A}_{i}} P(a_{i} | y) \log  \frac{P(a_{i},y)}{P(a_{i})P(y)} = KL \big[\ P(\mathbb{A}_{i} | y) \Vert P(\mathbb{A}_{i}) \big]\</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">i_max</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>

    <span class="n">mu_syn</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">]</span>
    <span class="n">log_var_syn</span> <span class="o">=</span> <span class="n">log_var</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">]</span>
    <span class="n">i_max</span> <span class="o">=</span> <span class="n">kl_div</span><span class="p">(</span><span class="n">mu_syn</span><span class="p">,</span> <span class="n">log_var_syn</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">i_max</span>
</code></pre></div></div>
<p>test</p>

<script type="math/tex; mode=display">\mathcal{L}_{elbo}(\theta,\phi,x) =  E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}(x | z) \big]\ - KL \big[\ q_{\phi}(z | x) \Vert p(z) \big]\</script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mathcal{L}_{new}(\theta,\phi,x) &= \frac{1}{N}\sum^{N}_{i=1} \bigg[\ E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}(x^{(i)} | z) \big]\ \bigg]\ - KL \big[\ q_{\phi}(z_{n}) \Vert p(z_{n}) \big]\ - I(x_{n};z) \nonumber \\
& \underbrace{- \alpha I(x_{n};z)}_\text{Penalise} + \alpha \sum_{x \in X} p(X=x) \max_{i} KL \big[\ q_{\phi}(\mathbb{A}_{i} | x){p(\mathbb{A}_{i})}) 
\end{align} %]]></script>

<script type="math/tex; mode=display">\mathcal{L}_{new}( \theta,\phi,x ) =  \underbrace{E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}( x | z ) \big]\ - KL \big[\ q_{\phi}( z | x) \Vert p (z)\big]\ }_{\mathcal{L}_{elbo}}- \underbrace{\alpha KL \big[\ q_{\phi}(\mathbb{A}_{worst} | x) \Vert p(\mathbb{A}_{worst})\big]\ }_{\alpha*\text{Imax}}</script>

<p><img src="http://localhost:4000/images/nips_latents.png" alt="results" /></p>
:ET