<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.18.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Non-Synergistic Variational Auto-Encoders - Gonzalo Barrientos</title>
<meta name="description" content="Generative Modeling, Variational Inference ">


  <meta name="author" content="Gonzalo Barrientos">


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Gonzalo Barrientos">
<meta property="og:title" content="Non-Synergistic Variational Auto-Encoders">
<meta property="og:url" content="http://localhost:4000/non-syn-vae/">


  <meta property="og:description" content="Generative Modeling, Variational Inference ">







  <meta property="article:published_time" content="2019-01-01T00:00:00+00:00">





  

  


<link rel="canonical" href="http://localhost:4000/non-syn-vae/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Gonzalo Barrientos",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Gonzalo Barrientos Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Gonzalo Barrientos
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/posts/" >Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/talks/" >Talks</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/images/photo_gonzalo.png" alt="Gonzalo Barrientos" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Gonzalo Barrientos</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>ML Engineer at Clyde &amp; Co.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">London, UK</span>
        </li>
      

      
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/gonzalob90" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
          
            <li><a href="https://linkedin.com/in/gonzalobarrientos" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> Linkedin</a></li>
          
        
          
            <li><a href="https://twitter.com/gonzalo90" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
          
        
      

      

      
        <li>
          <a href="mailto:gonzalo.b90@gmail.com">
            <meta itemprop="email" content="gonzalo.b90@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Non-Synergistic Variational Auto-Encoders">
    <meta itemprop="description" content="Generative Modeling, Variational Inference">
    <meta itemprop="datePublished" content="2019-01-01T00:00:00+00:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Non-Synergistic Variational Auto-Encoders
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  3 minute read

</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <h3 id="work-presented-at-neurips-2018-workshop-latinx-in-ai">Work presented at NeurIPS 2018, Workshop LatinX in AI</h3>

<p>Our world is hierarchical and compositional, humans can generalise better since we use primitive
concepts that allow us to create complex representations (Higgins et al. (2016)).<br />
Towards the creation of truly intelligent systems, they should learn in a similar way resulting in an 
increase of their performance since they would capture the underlying factors of variation of the data 
( Bengio et al.(2013); Hassabis et al. (2017)).</p>

<p>According to Lake et al. (2016), a compositional representation should create new elements from 
the combination of primitive concepts resulting in a infinite number of new representations.  For 
example if our model is trained with images of white wall and then is presented a boy with a white 
shirt, it should identify the color white as a primitive element.</p>

<p>Furthermore, a disentangled representation has been interpreted in different ways, for instance Bengio et al. (2013) 
define it as one where single latent variables are sensitive to changes in generative factors, while being 
invariant to changes in other factors.</p>

<p>The original Variational auto-encoder (VAE) framework (Kingma &amp; Welling (2013); Rezende et al.(2014)) has been used 
extensively for the task of disentanglement by modifying the original ELBO formulation; for instance β-VAE, presented in Higgins et al. (2017a), 
increases the latent capacity by penalising the KL divergence term with a β hyperparameter.</p>

<script type="math/tex; mode=display">\mathcal{L}_{elbo}(\theta,\phi,x) =  E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}(x | z) \big]\ - KL \big[\ q_{\phi}(z | x) \Vert p(z) \big]\</script>

<script type="math/tex; mode=display">\mathcal{L}_{\beta-vae}(\theta,\phi,x) =  E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}(x | z) \big]\ - \beta * KL \big[\ q_{\phi}(z | x) \Vert p(z) \big]\</script>

<p>We proposed a new approach for the task mentioned above which, inspired in the concepts from neuroscience and information theory, penalises</p>

<script type="math/tex; mode=display">\begin{equation}
I(S; R_{1},R_{2}) = \underbrace{SI(S;R_{1},R_{2})}_\text{Redundant} + \underbrace{Unq(S;R_{1} \setminus{R_{2}})}_\text{Unique} + \underbrace{Unq(S;R_{2} \setminus{R_{1}})}_\text{Unique} + \underbrace{Syn(S;R_{1},R_{2})}_\text{Synergistic}
\end{equation}</script>

<p>For neural codes there are three types of independence when it comes to the relation between stimuli
and responses; which are the activity independence, the conditional independence and the information 
independence.  One of the first measures of synergy for sets of sources of information came from 
this notion of independence. In Williams &amp; Beer (2010) it is stated that if the responses come 
from different features of the stimulus, the information encoded in those responses should be added 
to estimate the mutual information they provide about the stimulus. Formally:</p>

<p>What about a <a href="https://google.com">link</a></p>

<p><img src="http://localhost:4000/images/population.png" alt="population coding" /></p>

<p>The intuition behind this metric is that synergy should be defined as the “whole beyond the 
maximum of its parts”. The whole is described as the mutual information between the joint $\textbf{X}$ 
and the outcome Y; whereas the maximum of all the possible subsets is interpreted as the maximum information 
that any of the sources $\sA_{i}$ provided about each outcome. Formally, this is stated as:</p>

<p>However, we just saw in the previous sections that theI(S;R1)andI(S;R2)could be decomposed 
in their unique and redundant and synergistic terms. Intuitively, this formulation only holds if there 
is no redundant or synergistic information present; which means in the context of population coding 
that the responses encoded different parts of the stimulus. If the responses R1 and R2 convey more 
information together than separate, we can say we have synergistic information; if the information 
is less, we have redundant information. That’s the reason why in Gat &amp; Tishby (1998), the synergy 
is considered as measure of information independence</p>

<script type="math/tex; mode=display">\begin{equation}
Syn(R_{1}, R_{2}) = I(S; R_{1}, R_{2}) - I(S;R_{1}) - I(S;R_{2})
\end{equation}</script>

<p><img src="http://localhost:4000/images/synergy_3_latens.png" alt="results" /></p>

<script type="math/tex; mode=display">\require{physics}</script>

<p>n: Number of individual predictors $X_{i}$
$\sA_{i}$ : subset of individual predictors (ie. $A_{i} = {X_{1},X_{3}}$)
\textbf{X}: Joint random variable of all individual predictors $X_{1}X_{2}..X_{n}$
${X_{1},X_{2},…,X_{n}}$: Set of all the individual predictors
Y: Random variable to be predicted
y: A particular outcome of Y.</p>

<script type="math/tex; mode=display">S_{max}(\{X_{1},X_{2},...,X_{n}\};Y) = I(X; Y) - \sum_{y \in Y} p(Y=y) \max_{i} KL \big[\ P(A_{i} | y) \Vert P(A_{i}) \big]\</script>

<script type="math/tex; mode=display">I(\mathbb{A}_{i};Y=y) = \sum_{a_{i} \in \mathbb{A}_{i}} P(a_{i} | y) \log  \frac{P(a_{i},y)}{P(a_{i})P(y)} = KL \big[\ P(\mathbb{A}_{i} | y) \Vert P(\mathbb{A}_{i}) \big]\</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">i_max</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>

    <span class="n">mu_syn</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">]</span>
    <span class="n">log_var_syn</span> <span class="o">=</span> <span class="n">log_var</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">]</span>
    <span class="n">i_max</span> <span class="o">=</span> <span class="n">kl_div</span><span class="p">(</span><span class="n">mu_syn</span><span class="p">,</span> <span class="n">log_var_syn</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">i_max</span>
</code></pre></div></div>

<script type="math/tex; mode=display">\begin{equation}
KL \big[\ q_{\phi}(z_{2}z_{5}z_{8} | x) \Vert p(z_{2}z_{5}z_{8}) \big]\
\end{equation}</script>

<script type="math/tex; mode=display">\mathcal{L}_{elbo}(\theta,\phi,x) =  E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}(x | z) \big]\ - KL \big[\ q_{\phi}(z | x) \Vert p(z) \big]\</script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mathcal{L}_{new}(\theta,\phi,x) &= \frac{1}{N}\sum^{N}_{i=1} \bigg[\ E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}(x^{(i)} | z) \big]\ \bigg]\ - KL \big[\ q_{\phi}(z_{n}) \Vert p(z_{n}) \big]\ - I(x_{n};z) \nonumber \\
& \underbrace{- \alpha I(x_{n};z)}_\text{Penalise} + \alpha \sum_{x \in X} p(X=x) \max_{i} KL \big[\ q_{\phi}(\mathbb{A}_{i} | x){p(\mathbb{A}_{i})}) 
\end{align} %]]></script>

<script type="math/tex; mode=display">\mathcal{L}_{new}( \theta,\phi,x ) =  \underbrace{E_{q_{\phi}(z | x)} \big[\ \log p_{\theta}( x | z ) \big]\ - KL \big[\ q_{\phi}( z | x) \Vert p (z)\big]\ }_{\mathcal{L}_{elbo}}- \underbrace{\alpha KL \big[\ q_{\phi}(\mathbb{A}_{worst} | x) \Vert p(\mathbb{A}_{worst})\big]\ }_{\alpha*\text{Imax}}</script>

<p><img src="http://localhost:4000/images/traversal_mean_white.png" alt="results" /></p>

<h3 id="references">References:</h3>

<ul>
  <li>
    <p>Irina Higgins, Loıc Matthey, Xavier Glorot, Arka Pal, Benigno Uria, Charles Blundell, Shakir Mohamed,  and Alexander Lerchner.  Early visual concept learning with unsupervised deep learning.CoRR, abs/1606.05579, 2016</p>
  </li>
  <li>
    <p>Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman.   Building machines that learn and think like people.CoRR, abs/1604.00289, 2016. URL http://arxiv.org/abs/1604.00289.</p>
  </li>
  <li>
    <p>Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner.  dsprites:  Disentanglement testing sprites dataset. https://github.com/deepmind/dsprites-dataset/, 2017.</p>
  </li>
  <li>
    <p>Diederik P. Kingma and Max Welling.   Auto-encoding variational bayes.CoRR, abs/1312.6114,2013. URL http://arxiv.org/abs/1312.6114.</p>
  </li>
  <li>
    <p>Yoshua Bengio, Aaron C. Courville, and Pascal Vincent.   Representation learning:  A review and new perspectives.IEEE Trans. Pattern Anal. Mach. Intell.,  35(8):1798–1828,  2013.</p>
  </li>
  <li>
    <p>Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.   Stochastic backpropagation and approximate inference in deep generative models.  In Proceedings of the 31th International Conference on Machine Learning, ICML 2014. URL http://jmlr.org/proceedings/papers/v32/rezende14.html.</p>
  </li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#generative-modeling" class="page__taxonomy-item" rel="tag">generative modeling</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#variational-inference" class="page__taxonomy-item" rel="tag">variational inference</a>
    
    </span>
  </p>




        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2019-01-01T00:00:00+00:00">January 1, 2019</time></p>
        
      </footer>

      

      
    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          
            
      </div>
    </div>
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Gonzalo Barrientos. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>










<script>
MathJax = {
  loader: {
    load: ['input/tex-base', 'output/svg', 'ui/menu', '[tex]/physics']
  },
  tex: {
    packages: ['base', 'require', 'physics']
  }
};
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




  </body>
</html>
